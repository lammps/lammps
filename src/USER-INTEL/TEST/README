#############################################################################
# Benchmarks
#
# in.intel.lj -		Atomic fluid (LJ Benchmark)
# in.intel.rhodo -	Protein (Rhodopsin Benchmark)
# in.intel.lc -	 	Liquid Crystal w/ Gay-Berne potential
# in.intel.sw -		Silicon benchmark with Stillinger-Weber
# in.intel.tersoff -	Silicon benchmark with Tersoff
# in.intel.water - 	Coarse-grain water benchmark using Stillinger-Weber
#
#############################################################################

#############################################################################
# Expected Timesteps/second on E5-2697v3 with turbo on and HT enabled
#
# in.intel.lj -		131.943
# in.intel.rhodo -	8.661
# in.intel.lc -	 	14.015
# in.intel.sw -		103.53
# in.intel.tersoff -	55.525
# in.intel.water - 	44.079
#
#############################################################################

#############################################################################
# For Haswell and Broadwell architectures, depending on the compiler version, 
# it may give better performance to compile for an AVX target (with -xAVX 
# compiler option) instead of -xHost or -xCORE-AVX2 for some of the 
# workloads due to inefficient code generation for gathers. Aside from
# Tersoff, this will not significantly impact performance because FMA 
# sensitive routines will still use AVX2 (MKL and SVML detect the processor 
# at runtime)
#############################################################################

#############################################################################
# The default benchmark timesteps will run between 30s and 1 minute with
# the Intel package. You can specify a multiplier for all of the benchmarks
# to increase or decrease the runtime. Example commandline arguments:
#
# -v m 2		# Run for twice as long
# -v m 0.5		# Run for half as long
#############################################################################

#	Example for running benchmarks:

# 	Number of physical cores per node not including hyperthreads
export LMP_CORES=28

#      If hyperthreading is enabled, number of hyperthreads to use per core
#      (2 for Xeon; 2 or 4 for Xeon Phi)
export OMP_NUM_THREADS=2
                        
#      Name of the LAMMPS binary
export LMP_BIN=../../lmp_intel_cpu

#      LAMMPS root directory
export LMP_ROOT=../../../
               
source /opt/intel/parallel_studio_xe_2016.2.062/psxevars.sh
export I_MPI_PIN_DOMAIN=core
export I_MPI_FABRICS=shm		# For single node

#      Generate the restart file for use with liquid crystal benchmark
mpirun -np $LMP_CORES $LMP_BIN -in in.lc_generate_restart -log none

#      Benchmark to run
export bench=in.intel.lj


#############################################################################
# To run without a optimization package
#############################################################################
mpirun -np $LMP_CORES $LMP_BIN -in $bench -log none

#############################################################################
# To run with USER-OMP package
#############################################################################
mpirun -np $LMP_CORES $LMP_BIN -in $bench -log none -pk omp 0

#############################################################################
# To run with USER-INTEL package and no coprocessor
#############################################################################
mpirun -np $LMP_CORES $LMP_BIN -in $bench -log none -pk intel 0

#############################################################################
# To run with USER-INTEL and automatic load balancing to 1 coprocessor
#############################################################################
mpirun -np $LMP_CORES $LMP_BIN -in $bench -log none -pk intel 1
